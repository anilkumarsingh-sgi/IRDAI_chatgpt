"""
IRDAI Compliance GPT â€“ Streamlit Application
Uses HuggingFace Inference API + ChromaDB RAG
"""

import os
import time
import logging
import sqlite3
from pathlib import Path

import streamlit as st
from huggingface_hub import InferenceClient

from ingestion import retrieve_relevant_chunks, get_chroma_collection, CHROMA_DIR
from crawler import get_download_stats, DB_PATH, init_db, PDF_DIR, EXCEL_DIR, WORD_DIR

# â”€â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("irdai.app")

# â”€â”€â”€ Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title = "IRDAI Compliance GPT",
    page_icon  = "ğŸ›ï¸",
    layout     = "wide",
    initial_sidebar_state = "expanded",
)

# â”€â”€â”€ Custom CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
  /* â”€â”€ Google Fonts â”€â”€ */
  @import url('https://fonts.googleapis.com/css2?family=Syne:wght@400;600;700;800&family=IBM+Plex+Mono:wght@400;500&family=Inter:wght@400;500&display=swap');

  html, body, [class*="css"] { font-family: 'Inter', sans-serif; }

  /* â”€â”€ Root palette â”€â”€ */
  :root {
    --bg:        #0B0F1A;
    --surface:   #111827;
    --border:    #1F2D40;
    --accent:    #00C6A2;
    --accent2:   #3B82F6;
    --warn:      #F59E0B;
    --danger:    #EF4444;
    --text:      #E2E8F0;
    --muted:     #94A3B8;
  }

  /* â”€â”€ App background â”€â”€ */
  .stApp { background: var(--bg); color: var(--text); }

  /* â”€â”€ Sidebar â”€â”€ */
  [data-testid="stSidebar"] {
    background: var(--surface) !important;
    border-right: 1px solid var(--border);
  }

  /* â”€â”€ Title banner â”€â”€ */
  .title-banner {
    background: linear-gradient(135deg, #0F2027, #203A43, #2C5364);
    border: 1px solid var(--border);
    border-radius: 12px;
    padding: 28px 36px;
    margin-bottom: 28px;
    position: relative;
    overflow: hidden;
  }
  .title-banner::after {
    content: '';
    position: absolute;
    top: -40px; right: -40px;
    width: 220px; height: 220px;
    background: radial-gradient(circle, rgba(0,198,162,.18), transparent 70%);
    border-radius: 50%;
  }
  .title-banner h1 {
    font-family: 'Syne', sans-serif;
    font-size: 2rem;
    font-weight: 800;
    color: var(--accent);
    margin: 0;
    letter-spacing: -0.5px;
  }
  .title-banner p {
    color: var(--muted);
    margin: 6px 0 0;
    font-size: .9rem;
  }

  /* â”€â”€ Metric cards â”€â”€ */
  .metric-card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 18px 22px;
    text-align: center;
  }
  .metric-card .val {
    font-family: 'Syne', sans-serif;
    font-size: 1.8rem;
    font-weight: 700;
    color: var(--accent);
  }
  .metric-card .lbl {
    font-size: .75rem;
    color: var(--muted);
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-top: 4px;
  }

  /* â”€â”€ Question input â”€â”€ */
  .stTextArea textarea {
    background: var(--surface) !important;
    color: var(--text) !important;
    border: 1px solid var(--border) !important;
    border-radius: 8px !important;
    font-family: 'Inter', sans-serif !important;
  }
  .stTextArea textarea:focus {
    border-color: var(--accent) !important;
    box-shadow: 0 0 0 2px rgba(0,198,162,.2) !important;
  }

  /* â”€â”€ Buttons â”€â”€ */
  .stButton>button {
    background: linear-gradient(135deg, var(--accent), #00A88A) !important;
    color: #0B0F1A !important;
    font-weight: 600 !important;
    font-family: 'Syne', sans-serif !important;
    border: none !important;
    border-radius: 8px !important;
    padding: 10px 28px !important;
    letter-spacing: .4px;
    transition: opacity .2s;
  }
  .stButton>button:hover { opacity: .88; }

  /* â”€â”€ Answer card â”€â”€ */
  .answer-card {
    background: var(--surface);
    border: 1px solid var(--accent);
    border-radius: 10px;
    padding: 24px 28px;
    margin-top: 20px;
    line-height: 1.75;
  }

  /* â”€â”€ Source citation badge â”€â”€ */
  .cite-badge {
    display: inline-flex;
    align-items: center;
    gap: 6px;
    background: rgba(59,130,246,.12);
    border: 1px solid rgba(59,130,246,.3);
    border-radius: 6px;
    padding: 4px 10px;
    font-size: .78rem;
    font-family: 'IBM Plex Mono', monospace;
    color: #93C5FD;
    margin: 4px 4px 4px 0;
  }

  /* â”€â”€ Disclaimer â”€â”€ */
  .disclaimer {
    background: rgba(245,158,11,.07);
    border: 1px solid rgba(245,158,11,.3);
    border-radius: 8px;
    padding: 14px 18px;
    font-size: .82rem;
    color: #FCD34D;
    margin-top: 28px;
  }

  /* â”€â”€ Sidebar info blocks â”€â”€ */
  .sb-block {
    background: rgba(0,198,162,.06);
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 12px 14px;
    margin-bottom: 10px;
    font-size: .83rem;
  }
  .sb-block .sb-title {
    font-family: 'Syne', sans-serif;
    font-size: .75rem;
    color: var(--accent);
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: 6px;
  }

  /* â”€â”€ Spinner â”€â”€ */
  [data-testid="stSpinner"] { color: var(--accent) !important; }

  /* Status pills â”€â”€ */
  .pill-ok  { color: #34D399; font-weight: 600; }
  .pill-err { color: var(--danger); font-weight: 600; }
</style>
""", unsafe_allow_html=True)


# â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_hf_token() -> str:
    """Read HF token from st.secrets or env."""
    try:
        return st.secrets["HF_TOKEN"]
    except Exception:
        token = os.getenv("HF_TOKEN", "")
        if not token:
            st.error("âš ï¸ HF_TOKEN not found. Add it in Streamlit Cloud â†’ Secrets.")
        return token


MODEL_ID = "mistralai/Mistral-7B-Instruct-v0.2"

SYSTEM_PROMPT = (
    "You are an expert IRDAI (Insurance Regulatory and Development Authority of India) compliance assistant. "
    "Answer questions based ONLY on the provided regulatory context. "
    "Be precise, cite relevant regulation sections, and keep the answer professional. "
    "If the context does not contain sufficient information, say so clearly."
)


@st.cache_resource(show_spinner=False)
def get_hf_client(token: str) -> InferenceClient:
    """Create a cached HuggingFace InferenceClient."""
    return InferenceClient(model=MODEL_ID, token=token)


def run_rag_query(query: str, token: str) -> dict:
    """
    Full RAG pipeline:
      1. Retrieve relevant chunks
      2. Build context string
      3. Call HF Inference API
      4. Return answer + citations
    """
    chunks = retrieve_relevant_chunks(query, n_results=5)

    if not chunks:
        return {
            "answer":    "âš ï¸ No documents found in the knowledge base. Please run the crawler and ingestion pipeline first.",
            "citations": [],
        }

    context = "\n\n---\n\n".join(
        f"[{c['source']} | Page {c['page']}]\n{c['text']}"
        for c in chunks
    )

    user_message = (
        f"CONTEXT:\n{context}\n\n"
        f"QUESTION:\n{query}\n\n"
        f"Provide a clear, structured, compliance-focused answer."
    )

    try:
        client = get_hf_client(token)
        response = client.chat_completion(
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user",   "content": user_message},
            ],
            max_tokens=1024,
            temperature=0.3,
        )
        answer = response.choices[0].message.content
    except Exception as exc:
        logger.error("LLM call failed: %s", exc)
        error_msg = str(exc).lower()
        if "rate limit" in error_msg or "429" in error_msg:
            answer = (
                "â³ HuggingFace API rate limit reached. "
                "Please wait ~60 seconds and try again, or upgrade your HF plan."
            )
        else:
            answer = f"âŒ LLM error: {exc}"

    citations = [
        {"source": c["source"], "page": c["page"], "score": c["score"]}
        for c in chunks
    ]

    return {"answer": answer.strip(), "citations": citations}


def get_collection_stats() -> dict:
    """Get vector store doc count."""
    try:
        col = get_chroma_collection()
        return {"count": col.count(), "status": "ok"}
    except Exception:
        return {"count": 0, "status": "error"}


def get_file_counts() -> dict:
    """Count actual files on disk by type."""
    counts = {"pdf": 0, "excel": 0, "word": 0}
    if PDF_DIR.exists():
        counts["pdf"] = len(list(PDF_DIR.rglob("*.pdf")))
    if EXCEL_DIR.exists():
        counts["excel"] = len(list(EXCEL_DIR.rglob("*.xlsx"))) + len(list(EXCEL_DIR.rglob("*.xls")))
    if WORD_DIR.exists():
        counts["word"] = len(list(WORD_DIR.rglob("*.docx"))) + len(list(WORD_DIR.rglob("*.doc")))
    return counts


def get_sqlite_stats() -> dict:
    """Get download stats from SQLite."""
    try:
        init_db()
        return get_download_stats()
    except Exception:
        return {}


# â”€â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.markdown("""
    <div style='font-family:Syne,sans-serif;font-size:1.1rem;font-weight:700;
                color:#00C6A2;padding:8px 0 18px;letter-spacing:-.3px;'>
      ğŸ›ï¸ IRDAI Compliance GPT
    </div>
    """, unsafe_allow_html=True)

    # System Status
    col_stats = get_collection_stats()
    db_stats  = get_sqlite_stats()
    file_counts = get_file_counts()
    total_docs = sum(file_counts.values())
    vec_count  = col_stats["count"]
    vec_status_cls = "pill-ok" if col_stats["status"] == "ok" and vec_count > 0 else "pill-err"

    st.markdown(f"""
    <div class="sb-block">
      <div class="sb-title">System Status</div>
      <div>Vector DB &nbsp;<span class="{vec_status_cls}">{'âœ“ ' + str(vec_count) + ' chunks' if vec_count > 0 else 'âœ— Empty'}</span></div>
      <div>Total Docs &nbsp;<b style="color:#E2E8F0">{total_docs}</b></div>
    </div>
    """, unsafe_allow_html=True)

    # Document inventory by type
    st.markdown('<div class="sb-block"><div class="sb-title">Document Inventory</div>', unsafe_allow_html=True)
    st.markdown(f'<div>ğŸ“„ PDFs: <b style="color:#E2E8F0">{file_counts["pdf"]}</b></div>', unsafe_allow_html=True)
    st.markdown(f'<div>ğŸ“Š Excel: <b style="color:#E2E8F0">{file_counts["excel"]}</b></div>', unsafe_allow_html=True)
    st.markdown(f'<div>ğŸ“ Word: <b style="color:#E2E8F0">{file_counts["word"]}</b></div>', unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)

    # Category breakdown from DB
    if db_stats:
        st.markdown('<div class="sb-block"><div class="sb-title">Download Categories</div>', unsafe_allow_html=True)
        for cat, cnt in db_stats.items():
            st.markdown(f"<div>ğŸ“ {cat}: <b style='color:#E2E8F0'>{cnt}</b></div>", unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

    st.divider()

    # Admin actions
    st.markdown("### âš™ï¸ Admin Actions")
    if st.button("ğŸ•·ï¸ Run Crawler"):
        from crawler import run_crawl
        with st.spinner("Crawling IRDAI websiteâ€¦"):
            summary = run_crawl()
        st.success(f"Crawl done â€” PDFs: {summary.get('pdf',0)}, Excel: {summary.get('excel',0)}, Word: {summary.get('word',0)}")

    if st.button("ğŸ“¥ Run Ingestion"):
        from ingestion import run_ingestion
        with st.spinner("Ingesting documents into vector storeâ€¦"):
            summary = run_ingestion()
        st.success(
            f"Ingested {summary['total_files']} files â†’ {summary['total_chunks']} chunks\n"
            f"(PDF: {summary.get('pdf',0)}, Excel: {summary.get('excel',0)}, Word: {summary.get('word',0)})"
        )

    st.divider()
    st.markdown("""
    <div class="sb-block">
      <div class="sb-title">Model Info</div>
      <div style="font-size:.78rem;color:#94A3B8;line-height:1.6">
        LLM: mistralai/Mistral-7B-Instruct-v0.2<br>
        Embedding: all-MiniLM-L6-v2<br>
        Vector DB: ChromaDB (local)<br>
        Backend: HuggingFace Inference API
      </div>
    </div>
    """, unsafe_allow_html=True)


# â”€â”€â”€ Main Content â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<div class="title-banner">
  <h1>ğŸ›ï¸ IRDAI Compliance GPT</h1>
  <p>Regulatory Intelligence System Â· Powered by HuggingFace + RAG Â· For internal compliance use only</p>
</div>
""", unsafe_allow_html=True)

# â”€â”€ Metrics row
c1, c2, c3, c4, c5 = st.columns(5)
col_stats_now = get_collection_stats()
file_counts_now = get_file_counts()
total_docs_now = sum(file_counts_now.values())

with c1:
    st.markdown(f'<div class="metric-card"><div class="val">{file_counts_now["pdf"]}</div><div class="lbl">PDFs</div></div>', unsafe_allow_html=True)
with c2:
    st.markdown(f'<div class="metric-card"><div class="val">{file_counts_now["excel"]}</div><div class="lbl">Excel Files</div></div>', unsafe_allow_html=True)
with c3:
    st.markdown(f'<div class="metric-card"><div class="val">{file_counts_now["word"]}</div><div class="lbl">Word Docs</div></div>', unsafe_allow_html=True)
with c4:
    st.markdown(f'<div class="metric-card"><div class="val">{col_stats_now["count"]}</div><div class="lbl">Vector Chunks</div></div>', unsafe_allow_html=True)
with c5:
    status_txt = "ğŸŸ¢ Ready" if col_stats_now["count"] > 0 else "ğŸ”´ Not Ready"
    st.markdown(f'<div class="metric-card"><div class="val" style="font-size:1.2rem">{status_txt}</div><div class="lbl">System Status</div></div>', unsafe_allow_html=True)

st.markdown("<br>", unsafe_allow_html=True)

# â”€â”€ Query section
st.markdown("### ğŸ’¬ Ask a Compliance Question")
st.caption("Query IRDAI regulations, circulars, notifications and guidelines using natural language.")

example_queries = [
    "What are the solvency margin requirements for life insurers?",
    "Explain IRDAI guidelines on electronic insurance accounts.",
    "What are the rules for reinsurance arrangements under IRDAI?",
    "What is the process for filing complaints under the Grievance Redressal mechanism?",
]

col_q, col_eg = st.columns([3, 1])
with col_q:
    user_query = st.text_area(
        "Your question",
        height=110,
        placeholder="e.g. What are the minimum capital requirements for a general insurer?",
        label_visibility="collapsed",
    )

with col_eg:
    st.markdown("**ğŸ’¡ Examples**")
    for eq in example_queries[:3]:
        if st.button(eq[:48] + "â€¦", key=eq, use_container_width=True):
            user_query = eq

col_btn, col_pad = st.columns([1, 4])
with col_btn:
    submit = st.button("ğŸ”  Ask IRDAI GPT", use_container_width=True)

# â”€â”€ RAG execution
if submit and user_query.strip():
    token = get_hf_token()
    if token:
        with st.spinner("ğŸ” Retrieving relevant regulations & generating answerâ€¦"):
            t0     = time.time()
            result = run_rag_query(user_query, token)
            elapsed = round(time.time() - t0, 2)

        answer    = result["answer"]
        citations = result["citations"]

        # Answer card
        st.markdown(f'<div class="answer-card">{answer}</div>', unsafe_allow_html=True)

        # Citations
        if citations:
            st.markdown("#### ğŸ“ Source Citations")
            badges_html = ""
            seen = set()
            for c in citations:
                key = f"{c['source']}_p{c['page']}"
                if key not in seen:
                    seen.add(key)
                    badges_html += (
                        f'<span class="cite-badge">'
                        f'ğŸ“„ {c["source"]} &nbsp;Â·&nbsp; Page {c["page"]} '
                        f'&nbsp;Â·&nbsp; Score {c["score"]:.2f}'
                        f'</span>'
                    )
            st.markdown(badges_html, unsafe_allow_html=True)

        st.caption(f"â± Response generated in {elapsed}s")

elif submit and not user_query.strip():
    st.warning("Please enter a question before submitting.")

# â”€â”€ Disclaimer
st.markdown("""
<div class="disclaimer">
  âš ï¸ <strong>Disclaimer:</strong> This tool is for internal compliance use only by authorised personnel (underwriting, claims, compliance teams).
  It processes only publicly available IRDAI documents and does <strong>not</strong> store or process any policyholder data.
  Responses are AI-generated and should be verified against official IRDAI publications before making compliance decisions.
</div>
""", unsafe_allow_html=True)
